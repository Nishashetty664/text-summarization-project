{"cells":[{"cell_type":"markdown","metadata":{"id":"i-kaSQnyLV1d"},"source":["**Mounting Google Drive**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reNrH1hZLNx3","outputId":"c6337021-e794-4da6-cb81-9730c86142d4","executionInfo":{"status":"ok","timestamp":1720249970438,"user_tz":-330,"elapsed":21654,"user":{"displayName":"Nisha","userId":"03743018001429071275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"y6aPzr-xLnrX"},"source":["**importing  libraries**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zvYAkNZML0l2","executionInfo":{"status":"ok","timestamp":1720249979733,"user_tz":-330,"elapsed":6917,"user":{"displayName":"Nisha","userId":"03743018001429071275"}}},"outputs":[],"source":["# Import pandas library for data manipulation\n","import pandas as pd\n","\n","# Import torch library for PyTorch functionalities\n","import torch\n","\n","# Importing DataLoader and Dataset from torch.utils.data enables creating my datasets and data loaders for efficient batch processing in PyTorch training loops.\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Import classes from transformers library for using T5 model and AdamW optimizer\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n","\n","# Import tqdm for displaying progress bars during training\n","from tqdm import tqdm\n"]},{"cell_type":"markdown","metadata":{"id":"H2q0Qyi7MCzg"},"source":["**Loading the train and validation data**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"P4uEtq2ZMI_m","executionInfo":{"status":"ok","timestamp":1720249985431,"user_tz":-330,"elapsed":4160,"user":{"displayName":"Nisha","userId":"03743018001429071275"}}},"outputs":[],"source":["# Load the train and validation data\n","train_data = pd.read_csv('/content/drive/My Drive/train_data1.csv')\n","val_data = pd.read_csv('/content/drive/My Drive/validate_data.csv')\n"]},{"cell_type":"markdown","metadata":{"id":"krkFRRGtMMFx"},"source":["**Defining the Mydataset class**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vIrH7JVxMS8j","executionInfo":{"status":"ok","timestamp":1720249987303,"user_tz":-330,"elapsed":2,"user":{"displayName":"Nisha","userId":"03743018001429071275"}}},"outputs":[],"source":["\n","class MyDataset(Dataset):\n","\n","    def __init__(self, data, tokenizer, max_input_length=512, max_output_length=150):#constructor of the MyDataset class, responsible for dataset handling and preparation for model training.\n","        self.data = data  # Initialize with the provided data\n","        self.tokenizer = tokenizer  # Set the tokenizer for encoding text\n","        self.max_input_length = max_input_length  # Maximum length for input sequences\n","        self.max_output_length = max_output_length  # Maximum length for output sequences\n","\n","    def __len__(self):\n","        return len(self.data)  # Return the total number of samples in the dataset\n","\n","    def __getitem__(self, idx): # responsible for retrieving a specific sample from your dataset at the given index (idx).\n","        article = self.data.iloc[idx]['article']  # Get the article text at the specified index\n","        highlight = self.data.iloc[idx]['highlight']  # Get the highlight (target summary) text at the specified index\n","\n","        # Encode the article text using the tokenizer, ensuring it fits within max_input_length\n","        inputs = self.tokenizer.encode_plus(\n","            article,\n","            max_length=self.max_input_length,\n","            padding='max_length',  # Pad to ensure all inputs are the same length\n","            truncation=True,  # Truncate if the text exceeds max_length\n","            return_tensors=\"pt\"  # Return PyTorch tensors\n","        )\n","\n","        # Encode the highlight text using the tokenizer, ensuring it fits within max_output_length\n","        targets = self.tokenizer.encode_plus(\n","            highlight,\n","            max_length=self.max_output_length,\n","            padding='max_length',  # Pad to ensure all targets are the same length\n","            truncation=True,  # Truncate if the text exceeds max_length\n","            return_tensors=\"pt\"  # Return PyTorch tensors\n","        )\n","\n","        # Return a dictionary containing the input_ids, attention_mask, and labels\n","        #flatten()to ensure that the tensors representing input_ids,attention_mask and labels are in a suitable format for training\n","        return {\n","            'input_ids': inputs.input_ids.flatten(),  # Flattened input_ids tensor\n","            'attention_mask': inputs.attention_mask.flatten(),  # Flattened attention_mask tensor\n","            'labels': targets.input_ids.flatten()  # Flattened labels (target sequences) tensor\n","        }\n","\n","    def display_data_size(self):\n","        print(f\"Dataset size: {len(self.data)}\")\n","\n","    def get_sample(self, idx):\n","        return self.__getitem__(idx)\n"]},{"cell_type":"markdown","source":["**Initializing the tokenizer and model**"],"metadata":{"id":"7p_jdQQjOVoa"}},{"cell_type":"code","source":["# Initialize the tokenizer and model\n","tokenizer = T5Tokenizer.from_pretrained('/content/drive/My Drive/fine_tuning')\n","model = T5ForConditionalGeneration.from_pretrained('/content/drive/My Drive/fine_tuning')\n"],"metadata":{"id":"SjYWP4_AOhaF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720249999080,"user_tz":-330,"elapsed":8839,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"b3376589-b1ba-4a37-afec-595ab82c6bfa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","source":["**Creating the dataset and dataloaders**"],"metadata":{"id":"V2I_0FLzOk7K"}},{"cell_type":"code","source":["# Create the dataset using the myDataset class for training data\n","train_dataset = MyDataset(train_data, tokenizer)\n","\n","# Create the dataset using the myDataset class for validation data\n","val_dataset = MyDataset(val_data, tokenizer)\n","\n","# Create a DataLoader for training dataset with batch size 8 and shuffle enabled (for random sampling)\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","\n","# Create a DataLoader for validation dataset with batch size 8 and shuffle disabled (for sequential sampling)\n","val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"],"metadata":{"id":"2yGsPbALOqLU","executionInfo":{"status":"ok","timestamp":1720249999081,"user_tz":-330,"elapsed":10,"user":{"displayName":"Nisha","userId":"03743018001429071275"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**Defining the optimizer and setting device**"],"metadata":{"id":"FMBdOSzyO5WG"}},{"cell_type":"code","source":["# Define the optimizer\n","optimizer = AdamW(model.parameters(), lr=6e-5)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n"],"metadata":{"id":"d1SVPPyuO-rQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720250004982,"user_tz":-330,"elapsed":1187,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"c077c53c-7ecf-4fb2-ef55-57262e65d881"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Initializing early stopping parameters**"],"metadata":{"id":"1x7CcSWBPBmd"}},{"cell_type":"code","source":["# Early stopping parameters\n","patience = 3  # Number of epochs with no improvement after which training will be stopped\n","best_val_loss = float('inf')  # Initialize the best validation loss to infinity\n","epochs_no_improve = 0  # Counter for epochs with no improvement\n"],"metadata":{"id":"-Tho8AG3PIqf","executionInfo":{"status":"ok","timestamp":1720250010495,"user_tz":-330,"elapsed":666,"user":{"displayName":"Nisha","userId":"03743018001429071275"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# TRAINING LOOP"],"metadata":{"id":"m7kpwnGfPMC3"}},{"cell_type":"code","source":["# Training loop for a single epoch\n","epochs = 1  # Maximum number of epochs to train (here only 1 epoch)\n","for epoch in range(epochs):\n","\n","    # Set the model in training mode\n","    model.train()\n","\n","    # Initialize the total training loss for this epoch\n","    train_loss = 0\n","\n","    # Initialize tqdm loop to display progress bar during training\n","    loop = tqdm(train_loader, leave=True)\n","\n","    # Iterate through each batch in the training DataLoader\n","    for batch in loop:\n","        # Move batch tensors to the appropriate device (CPU or GPU)\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Clear previously calculated gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass: compute model outputs and loss\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","\n","        # Backward pass: compute gradients\n","        loss.backward()\n","\n","        # Update model parameters\n","        optimizer.step()\n","\n","        # Accumulate the training loss\n","        train_loss += loss.item()\n","\n","        # Update tqdm progress bar description and postfix with current loss\n","        loop.set_description(f'Epoch {epoch+1}')\n","        loop.set_postfix(train_loss=loss.item())\n","\n","    # Calculate average training loss for this epoch\n","    avg_train_loss = train_loss / len(train_loader)\n","\n","    # Print average training loss for this epoch\n","    print(f'Average training loss: {avg_train_loss}')\n"],"metadata":{"id":"2oSoRQx7PQI5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720250579567,"user_tz":-330,"elapsed":565520,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"099f2e46-57b1-4f5f-feba-46131bf8ca60"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 1437/1437 [09:24<00:00,  2.54it/s, train_loss=1.14]"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.7568697169288298\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["***display training and validatin loss and save the model and tokenizer***"],"metadata":{"id":"UWqj8TG0SCgs"}},{"cell_type":"code","source":["# Training loop\n","epochs = 1  # Maximum number of epochs to train\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0\n","    loop = tqdm(train_loader, leave=True)\n","    for batch in loop:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        loop.set_description(f'Epoch {epoch+1}')\n","        loop.set_postfix(train_loss=loss.item())\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","    print(f'Average training loss: {avg_train_loss}')\n","\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            val_loss += loss.item()\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    print(f'Validation loss: {avg_val_loss}')\n","\n","    # Check if the validation loss improved\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        epochs_no_improve = 0\n","        # Save the model and tokenizer\n","        model.save_pretrained('/content/drive/My Drive/fine_tuning')\n","        tokenizer.save_pretrained('/content/drive/My Drive/fine_tuning')\n","        print(\"Model improved. Saving the model.\")\n","    else:\n","        epochs_no_improve += 1\n","        print(f'No improvement for {epochs_no_improve} epochs.')\n","\n","\n","    # Check if early stopping should be triggered\n","    if epochs_no_improve == patience:\n","        print(\"Early stopping triggered. Stopping training.\")\n","        break\n","\n","print(\"Training completed.\")\n"],"metadata":{"id":"9T6cjNjLPpG2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720251175192,"user_tz":-330,"elapsed":591013,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"b00aa781-6fee-465e-bc8d-c6dcc41fa5d2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 1437/1437 [09:18<00:00,  2.57it/s, train_loss=0.72]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.7505269895308367\n","Validation loss: 0.6532170535237701\n","Model improved. Saving the model.\n","Training completed.\n"]}]},{"cell_type":"markdown","source":["increasing epochs"],"metadata":{"id":"vKyh9Otw9i92"}},{"cell_type":"code","source":["# Training loop\n","epochs = 2  # Maximum number of epochs to train\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0\n","    loop = tqdm(train_loader, leave=True)\n","    for batch in loop:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        loop.set_description(f'Epoch {epoch+1}')\n","        loop.set_postfix(train_loss=loss.item())\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","    print(f'Average training loss: {avg_train_loss}')\n","\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            val_loss += loss.item()\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    print(f'Validation loss: {avg_val_loss}')\n","\n","    # Check if the validation loss improved\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        epochs_no_improve = 0\n","        # Save the model and tokenizer\n","        model.save_pretrained('/content/drive/My Drive/fine_tuning')\n","        tokenizer.save_pretrained('/content/drive/My Drive/fine_tuning')\n","        print(\"Model improved. Saving the model.\")\n","    else:\n","        epochs_no_improve += 1\n","        print(f'No improvement for {epochs_no_improve} epochs.')\n","\n","\n","    # Check if early stopping should be triggered\n","    if epochs_no_improve == patience:\n","        print(\"Early stopping triggered. Stopping training.\")\n","        break\n","\n","print(\"Training completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4mDA0RZ9R3r","executionInfo":{"status":"ok","timestamp":1720252456255,"user_tz":-330,"elapsed":1185740,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"d310e736-5866-4d62-fc2c-b148b0ea6739"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 1437/1437 [09:23<00:00,  2.55it/s, train_loss=0.934]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.7435482833106731\n","Validation loss: 0.6416343261522276\n","Model improved. Saving the model.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 1437/1437 [09:17<00:00,  2.58it/s, train_loss=0.607]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.7372110169134625\n","Validation loss: 0.6327376671963267\n","Model improved. Saving the model.\n","Training completed.\n"]}]},{"cell_type":"markdown","source":["# **EVALUATION**\n","\n","**Install the rouge-score package**"],"metadata":{"id":"7wtXndecQM1u"}},{"cell_type":"code","source":["!pip install rouge-score\n"],"metadata":{"id":"063hSDoqS3hZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720252471160,"user_tz":-330,"elapsed":7823,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"6fa58fb1-3047-439f-9e02-d4ec59dd5d1f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=166adcc202227fd8d5996d906aa9de6450901b036b521066073987dd834cd6ee\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}]},{"cell_type":"markdown","source":["## **ImportLibraries**"],"metadata":{"id":"BoIOsSLfTMu8"}},{"cell_type":"code","source":["\n","\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from tqdm import tqdm\n","from rouge_score import rouge_scorer\n","\n","# Define a custom dataset class\n","class MyDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_input_length=512, max_output_length=150):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_input_length = max_input_length\n","        self.max_output_length = max_output_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        article = self.data.iloc[idx]['article']\n","        highlight = self.data.iloc[idx]['highlight']\n","\n","        inputs = self.tokenizer.encode_plus(\n","            article,\n","            max_length=self.max_input_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        targets = self.tokenizer.encode_plus(\n","            highlight,\n","            max_length=self.max_output_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        return {\n","            'input_ids': inputs.input_ids.flatten(),\n","            'attention_mask': inputs.attention_mask.flatten(),\n","            'labels': targets.input_ids.flatten()\n","        }\n","\n","# Function to calculate ROUGE scores\n","def calculate_rouge_scores(hypotheses, references):\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","    rouge1_scores = []\n","    rouge2_scores = []\n","    rougeL_scores = []\n","\n","    for hyp, ref in zip(hypotheses, references):\n","        scores = scorer.score(hyp, ref)\n","        rouge1_scores.append(scores['rouge1'].fmeasure)\n","        rouge2_scores.append(scores['rouge2'].fmeasure)\n","        rougeL_scores.append(scores['rougeL'].fmeasure)\n","\n","    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n","    avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n","    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n","\n","    return avg_rouge1, avg_rouge2, avg_rougeL\n","\n","# Load the validation data\n","val_data = pd.read_csv('/content/drive/My Drive/validate_data.csv')\n","\n","# Initialize the tokenizer and model\n","tokenizer = T5Tokenizer.from_pretrained('/content/drive/My Drive/fine_tuning')\n","model = T5ForConditionalGeneration.from_pretrained('/content/drive/My Drive/fine_tuning')\n","\n","# Create the dataset and dataloader\n","val_dataset = MyDataset(val_data, tokenizer)\n","val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","# Initialize empty lists to store generated summaries and target summaries\n","hypotheses = []\n","references = []\n","# Disable gradient calculation for inference\n","with torch.no_grad():\n","  # Iterate over batches in the validation data loader with progress bar\n","    for batch in tqdm(val_loader):\n","      # Move batch tensors to the appropriate device (GPU if available)\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Generate summaries\n","        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150, num_beams=2, early_stopping=True)\n","         # Decode generated summaries and target summaries to text\n","        preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","        targets = [tokenizer.decode(l, skip_special_tokens=True, clean_up_tokenization_spaces=True) for l in labels]\n"," # Extend the hypotheses and references lists with the generated and target summaries\n","        hypotheses.extend(preds)\n","        references.extend(targets)\n","\n","# Calculate ROUGE scores\n","rouge1, rouge2, rougeL = calculate_rouge_scores(hypotheses, references)\n","\n","print(f'ROUGE-1: {rouge1:.4f} ROUGE-2: {rouge2:.4f} ROUGE-L: {rougeL:.4f}')\n"],"metadata":{"id":"ExiO1JCNTYDI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720252849501,"user_tz":-330,"elapsed":376148,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"cd7ca682-dc96-4c05-8833-d83bc8ee0367"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","100%|██████████| 216/216 [06:09<00:00,  1.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["ROUGE-1: 0.3970 ROUGE-2: 0.2024 ROUGE-L: 0.3125\n"]}]},{"cell_type":"markdown","source":["**example**"],"metadata":{"id":"VRahTM1XVev3"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# Load validation data (assuming 'val_data.csv' contains 'article' and 'highlight' columns)\n","val_data = pd.read_csv('/content/drive/My Drive/validate_data.csv')\n","\n","# Load the tokenizer and model\n","tokenizer = T5Tokenizer.from_pretrained('/content/drive/My Drive/fine_tuning')\n","model = T5ForConditionalGeneration.from_pretrained('/content/drive/My Drive/fine_tuning')\n","\n","# Set device to GPU if available, otherwise to CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Function to generate summaries\n","def generate_summary(article_text, tokenizer, model):\n","    inputs = tokenizer.encode_plus(\n","        article_text,\n","        max_length=512,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","\n","    # Generate summary\n","    summary_ids = model.generate(\n","        inputs.input_ids.to(device),\n","        attention_mask=inputs.attention_mask.to(device),\n","        max_length=150,\n","        num_beams=2,\n","        early_stopping=True\n","    )\n","\n","    # Decode the summary tokens to text\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","\n","    return summary\n","\n","# Select two records for demonstration\n","record1 = val_data.iloc[0]\n","record2 = val_data.iloc[1]\n","\n","# Generate summaries\n","summary1 = generate_summary(record1['article'], tokenizer, model)\n","summary2 = generate_summary(record2['article'], tokenizer, model)\n","\n","# Display the results\n","print(\"Record 1:\")\n","print(\"Article:\")\n","print(record1['article'])\n","print(\"\\nHighlight:\")\n","print(record1['highlight'])\n","print(\"\\nGenerated Summary:\")\n","print(summary1)\n","\n","print(\"\\n-------------------------------------------------\\n\")\n","\n","print(\"Record 2:\")\n","print(\"Article:\")\n","print(record2['article'])\n","print(\"\\nHighlight:\")\n","print(record2['highlight'])\n","print(\"\\nGenerated Summary:\")\n","print(summary2)\n","\n"],"metadata":{"id":"l54pWP-jWEw7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720106910761,"user_tz":-330,"elapsed":14111,"user":{"displayName":"Nisha","userId":"03743018001429071275"}},"outputId":"c9cb1e81-45e4-4a01-e671-dd7432e8a33f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["Record 1:\n","Article:\n","brendan rodgers deliver weekly briefing media friday afternoon previewing showdown arsenal saturday discussing future raheem sterling young england star moved step closer anfield exit revealing tv interview ready sign new contract anfield sterling 20 offered new 100000aweek contract stay club admitted flattered interest arsenal follow press conference happens 2pm host commentator brendan rodgers brought close broadcast section press conference rest quotes embargoed tonight summary rodgers insisted raheem sterling going anywhere summer focus moment purely football manager said relaxed contract situation liverpool superpower world football dont sell best players admit however sterlings interview conducted without prior consent club took surprise concentration weeks back purely focus football help continue development place hes made great strides last couple years last time sat plays representatives intention raheem come made feelings clear hopefully continue focus football end season said absolutely underpins everything trying achieve raheem says ambition win trophies thats perfectly aligned trying liverpool one great clubs football world honour play club like liverpool understands hes saying hes got two half years left hes quite relaxed wants concentrate football im quite relaxed part modern game people look players different ways working focus purely football involved first team two half years player today environment weve created hes got lot improvement best place hes going anywhere summer focus trying make best player money talk club shown thats case liverpool one superpowers football owners made clear weve seen money doesnt come club doesnt want sell wont sell thats case player raheem anybody else continuing nurture young player consistently playing top game raheem purely football hes made clear hes happy trying put talk hes boy loves football understands respects opportunity hes still two bit years left deal something weve overly concerned hopefully well get sorted interview permission club something surprised us hes young player learn sometimes makes mistakes relationship strong learn time goes make mistakes especially youre young moving back onto subject saturdays match arsenal rodgers says targeting least point trip emirates go game happy play game adds need keep ball better need technically better rodgers confirmed sterling permission club bbc interview surprised us admits learn make mistakes life especially young swiftly back burning issue liverpool one superpowers football money doesnt come club doesnt want sell doesnt sell money never objective raheem purely football kid trying put talk money conversation moves sterling saturdays match arsenal liverpool new injury worries jordan henderson back squad lucas available start reflecting damaging 21 loss manchester united international break left liverpool five points behind rivals rodgers says obviously disappointing result make sure perform arsenal contract talks two half years left deal hes going nowhere summer sterling linked arsenal rodgers says arsenal great club liverpool im quite relaxed part modern game raheem still lot improvements make great place subject raised straight away rodgers saying focus purely football thats concentration place hes made giant strides last years raheems ambition win trophies thats perfectly aligned trying one great clubs brendan rodgers arrived begin press briefing laurie whitwell sign raheem sterlings tender years seen inked forearm image wembley overlooked estate growing clear amid cluster tattoos rather two famous towers synonymous national stadium 77 years arc unveiled 2007 unmistakable back sterling young kid dreaming career professional football playing jumpers goalposts streets parks click read full story click see pictures training morning sportsmails riath alsamarrai reads lines discover sterling really thinking bbc interview click read ian ladyman raheem sterling edged closer towards exit liverpool wednesday night admitting tv interview ready sign new contract anfield sterling offered 100000aweek deal stay merseyside revealed bbc interview wednesday would signed lot less year ago indepth tv discussion liverpool knew nothing shortly aired 20yearold admitted quite flattering linked arsenal liverpool face saturday barclays premier league used dream playing abroad click read full story set pretty routine press conference liverpool manager brendan rodgers previewing saturdays game arsenal star player raheem sterling gave tv interview little suggest hed anfield next season 100000aweek contract tabled liverpool sterling isnt ready sign raising hopes suitors negotiations put ice summer rodgers expected give opinion 20yearolds ongoing contract saga well bring say 2pm\n","\n","Highlight:\n","rodgers hold press briefing ahead arsenal match 2pm sterling set dominate agenda moving closer anfield exit england star said ready sign new contract liverpool 20yearold offered 100000aweek deal stay read rise raheem sterling 60 day qpr knocking back 100000perweek contracts liverpool click latest liverpool fc news sterling contract saga reaction\n","\n","Generated Summary:\n","raheem sterling offered new 100000aweek contract stay anfield brendan rodgers insists relaxed contract situation liverpool superpower world football dont sell best players sterling offered new 100000aweek contract stay club\n","\n","-------------------------------------------------\n","\n","Record 2:\n","Article:\n","new york teacher fired allegedly encouraging pupils bully 13yearold girl writing worst qualities blackboard said victim terrible injustice wants job back madeline luciano said looked eighth grade pupils ps 18 manhattan wrote words like ugly annoying phony board describe classmate stopped girl started crying sacked madeline luciano pictured fired allegedly allowed pupils write nasty words one classmates board ms luciano fired following investigation claims far encouraging bully girl exercise supposed teach kinder 40yearold launched court action citys education department attempts get licence back work another school ms luciano told new york daily news want justice trying stop bullying insane dont deserve investigation incident took place last june revealed girl targeted bullies many times particular day hidden book bag injustice ms luciano claims actually trying teach lesson evils bullying ms luciano asked students write problems girl ended pupils shouting insults across classroom written board teacher worked new yorks education department since 2010 says things never meant go far told teen writing nasty comments board challenging eighthgrade students tried many different strategies modify behavior ms luciano told new york post\n","\n","Highlight:\n","madeline luciano fired investigation incident last june new york teacher claims exercise meant stop bullying luciano 40 launched court action get teaching licence back\n","\n","Generated Summary:\n","madeline luciano fired allegedly encouraging pupils bully 13yearold girl writing ugly annoying phony board ms luciano claims actually trying teach lesson evils bullying 40yearold launched court action citys education department\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMfzwmNoadiO3u5YB99m64E"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}