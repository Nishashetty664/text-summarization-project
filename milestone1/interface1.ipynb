{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce87485-5b23-4ea1-8218-4bc55759cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 833, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shett\\AppData\\Local\\Temp\\ipykernel_1788\\2453904518.py\", line 51, in summarize_text\n",
      "    text = extract_text_from_pdf(file.name)\n",
      "                                 ^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import gradio as gr\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "\n",
    "# Load the fine-tuned T5 model for abstractive summarization\n",
    "model_path = 'fine_tuning'\n",
    "abstractive_model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "abstractive_tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Function for abstractive summarization using the T5 model\n",
    "def abstractive_summarize(text):\n",
    "    inputs = abstractive_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = abstractive_model.generate(inputs, max_length=150, num_beams=4, early_stopping=True)\n",
    "    return abstractive_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Function for extractive summarization using the TextRank algorithm\n",
    "def extractive_summarize(text):\n",
    "    sentences = text.split(\".\")\n",
    "    \n",
    "    # Ensure there are enough sentences for summarization\n",
    "    if len(sentences) < 2:\n",
    "        return \"Not enough sentences to summarize.\"\n",
    "    \n",
    "    # Use CountVectorizer to transform sentences into vectors\n",
    "    vectorizer = CountVectorizer().fit_transform(sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    # Check if vectors are not empty and have the expected shape\n",
    "    if vectors.size == 0 or vectors.shape[0] < 2:\n",
    "        return \"Unable to compute summary due to insufficient data.\"\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarity_matrix = cosine_similarity(vectors)\n",
    "    \n",
    "    # Use PageRank algorithm to rank sentences\n",
    "    scores = nx.pagerank(nx.from_numpy_array(similarity_matrix))\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    \n",
    "    # Generate summary from top ranked sentences\n",
    "    summary = \" \".join([s[1] for s in ranked_sentences[:3]])  # Adjust summary length as needed\n",
    "    return summary\n",
    "\n",
    "# Function to determine summarization type based on user input\n",
    "def summarize_text(input_type, text, file, summarization_type):\n",
    "    if input_type == \"Text\":\n",
    "        text = text\n",
    "    elif input_type == \"PDF\":\n",
    "        text = extract_text_from_pdf(file.name)\n",
    "    else:\n",
    "        return \"Invalid input type selected.\"\n",
    "\n",
    "    if summarization_type == \"Abstractive\":\n",
    "        return abstractive_summarize(text)\n",
    "    elif summarization_type == \"Extractive\":\n",
    "        return extractive_summarize(text)\n",
    "\n",
    "# Function to extract text from a PDF file using PyMuPDF (fitz)\n",
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)  # Open PDF file from path\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Description content for the description page using Markdown\n",
    "description_content = \"\"\"\n",
    "<div class='description-content'>\n",
    "\n",
    "# WELLCOME TO TEXT SUMMIFY!! \n",
    "\n",
    "This interface allows you to summarize text using two different methods:\n",
    "\n",
    "## Abstractive Summarization\n",
    "This method generates a summary by interpreting the main ideas of the text and rephrasing them in a concise manner. It uses a fine-tuned T5 model to perform this task.\n",
    "\n",
    "## Extractive Summarization\n",
    "This method selects the most important sentences from the text and combines them to form a summary. It uses the TextRank algorithm for this purpose.\n",
    "\n",
    "To use the interface, choose the input type (Text or PDF), enter your text or upload a PDF file, select the type of summarization (Abstractive or Extractive), and click the \"Submit\" button to get your summary.\n",
    "\n",
    "## Features\n",
    "- Supports both abstractive and extractive summarization techniques.\n",
    "- Utilizes a fine-tuned T5 model for high-quality abstractive summaries.\n",
    "- Implements the TextRank algorithm for effective extractive summaries.\n",
    "- Easy-to-use interface with enhanced styling and graphics.\n",
    "\n",
    "## Discover the power of TEXT SUMMIFY today !! and streamline your interaction with textual information like never before!\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Define Gradio interface for summarization\n",
    "def input_type_change(input_type):\n",
    "    if input_type == \"Text\":\n",
    "        return gr.update(visible=True), gr.update(visible=False)\n",
    "    elif input_type == \"PDF\":\n",
    "        return gr.update(visible=False), gr.update(visible=True)\n",
    "\n",
    "with gr.Blocks() as summarize_interface:\n",
    "    gr.HTML(open(\"styles.html\").read())  # Include external HTML file for styles\n",
    "    gr.Markdown(\"# <span id='text-summify-heading'>TEXT SUMMIFY</span>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        input_type = gr.Radio([\"Text\", \"PDF\"], label=\"Input Type\", elem_id=\"input-type\")\n",
    "        summarization_type = gr.Dropdown(['Abstractive', 'Extractive'], label=\"Summarization Type\", elem_id=\"summarization-type\")\n",
    "    \n",
    "    text_input = gr.Textbox(lines=10, placeholder=\"Enter Text Here...\", visible=True, elem_id=\"input-area\")\n",
    "    pdf_input = gr.File(label=\"Upload PDF File\", visible=False, elem_id=\"input-area\")\n",
    "    \n",
    "    input_type.change(input_type_change, input_type, [text_input, pdf_input])\n",
    "    \n",
    "    summarize_button = gr.Button(\"Submit\", elem_id=\"btn-submit\")\n",
    "    clear_button = gr.Button(\"Clear\", elem_id=\"btn-clear\")\n",
    "    output = gr.Textbox(label=\"Summary\", elem_id=\"output-area\")\n",
    "    \n",
    "    def clear_function():\n",
    "        return \"\", None, \"\"\n",
    "\n",
    "    summarize_button.click(summarize_text, [input_type, text_input, pdf_input, summarization_type], output)\n",
    "    clear_button.click(clear_function, outputs=[text_input, pdf_input, output])\n",
    "\n",
    "# Define the description interface using Markdown\n",
    "description_interface = gr.Markdown(description_content)\n",
    "\n",
    "# Combine both interfaces into a tabbed interface\n",
    "combined_interface = gr.TabbedInterface(\n",
    "    [summarize_interface, description_interface],\n",
    "    [\"Summarize Text\", \"About TEXT SUMMIFY\"]\n",
    ")\n",
    "\n",
    "# Launch the combined interface\n",
    "combined_interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f043f-6712-4d74-9325-348e199e8879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
