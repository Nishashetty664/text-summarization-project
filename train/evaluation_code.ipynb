{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a080eb-15dd-4084-a35f-49f5afaab07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c0161c-6c09-449f-aef2-97b4f0cfb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, source_max_length=512, target_max_length=64):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_length = source_max_length\n",
    "        self.target_max_length = target_max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = str(self.data.iloc[idx]['cleaned_article'])\n",
    "        target_text = str(self.data.iloc[idx]['cleaned_highlights'])\n",
    "\n",
    "        source = self.tokenizer.encode_plus(\n",
    "            source_text,\n",
    "            max_length=self.source_max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        target = self.tokenizer.encode_plus(\n",
    "            target_text,\n",
    "            max_length=self.target_max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': source['input_ids'].flatten(),\n",
    "            'attention_mask': source['attention_mask'].flatten(),\n",
    "            'labels': target['input_ids'].flatten(),\n",
    "            'decoder_attention_mask': target['attention_mask'].flatten()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d109c2a6-a6f0-4c8a-a0c7-207a49025a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = [scorer.score(pred, ref) for pred, ref in zip(predictions, references)]\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927b94ab-55d3-4ad3-be56-19b1e7a81056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec31815-b765-4fa8-8e7b-a004c6d448d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = pd.read_csv('validate_split.csv')\n",
    "validation_dataset = TextDataset(validation_split, tokenizer)  # Assuming TextDataset is defined\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5023f7d6-1647-4174-928b-1996a3bbf77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████| 288/288 [30:16<00:00,  6.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1: 0.2964\n",
      "Average ROUGE-2 F1: 0.1179\n",
      "Average ROUGE-L F1: 0.2149\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(validation_loader, desc='Evaluating'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=64)\n",
    "        decoded_preds = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
    "        decoded_labels = [tokenizer.decode(ids, skip_special_tokens=True) for ids in labels]\n",
    "\n",
    "        predictions.extend(decoded_preds)\n",
    "        references.extend(decoded_labels)\n",
    "\n",
    "    rouge_scores = [rouge_scorer.score(pred, ref) for pred, ref in zip(predictions, references)]\n",
    "    avg_rouge1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n",
    "    avg_rouge2 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n",
    "    avg_rougeL = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n",
    "\n",
    "    print(f'Average ROUGE-1 F1: {avg_rouge1:.4f}')\n",
    "    print(f'Average ROUGE-2 F1: {avg_rouge2:.4f}')\n",
    "    print(f'Average ROUGE-L F1: {avg_rougeL:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8ca8ea-f055-4aa7-8017-aaddcff25d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article:\n",
      "The rise of artificial intelligence (AI) has brought both excitement and concern to various industries. In healthcare, AI is revolutionizing how diseases are diagnosed and treated. AI-powered algorithms can analyze medical images, such as X-rays and MRIs, with incredible accuracy, helping doctors detect diseases like cancer earlier than ever before. This early detection can significantly improve patient outcomes and save lives.\n",
      "\n",
      "In addition to diagnostics, AI is also being used to personalize treatment plans. By analyzing vast amounts of patient data, AI can recommend the most effective treatments based on individual factors like genetics and lifestyle. This personalized approach not only improves patient outcomes but also reduces healthcare costs by minimizing trial-and-error treatments.\n",
      "\n",
      "However, the widespread adoption of AI in healthcare also raises ethical and privacy concerns. Issues such as data security, bias in algorithms, and the impact on jobs are hotly debated topics. Despite these challenges, the potential of AI to revolutionize healthcare is undeniable. As technology continues to advance, AI is poised to play an increasingly vital role in improving patient care and advancing medical research.\n",
      "\n",
      "Generated Summary:\n",
      "AI can analyze medical images, such as X-rays and MRIs. this help doctors detect diseases like cancer earlier than ever before.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = 'fine_tuned_t5_model'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Define the article to summarize\n",
    "article = \"\"\"The rise of artificial intelligence (AI) has brought both excitement and concern to various industries. In healthcare, AI is revolutionizing how diseases are diagnosed and treated. AI-powered algorithms can analyze medical images, such as X-rays and MRIs, with incredible accuracy, helping doctors detect diseases like cancer earlier than ever before. This early detection can significantly improve patient outcomes and save lives.\n",
    "\n",
    "In addition to diagnostics, AI is also being used to personalize treatment plans. By analyzing vast amounts of patient data, AI can recommend the most effective treatments based on individual factors like genetics and lifestyle. This personalized approach not only improves patient outcomes but also reduces healthcare costs by minimizing trial-and-error treatments.\n",
    "\n",
    "However, the widespread adoption of AI in healthcare also raises ethical and privacy concerns. Issues such as data security, bias in algorithms, and the impact on jobs are hotly debated topics. Despite these challenges, the potential of AI to revolutionize healthcare is undeniable. As technology continues to advance, AI is poised to play an increasingly vital role in improving patient care and advancing medical research.\"\"\"\n",
    "\n",
    "# Function to generate summary\n",
    "def generate_summary(model, tokenizer, text, max_length=150):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Generate and display summary\n",
    "generated_summary = generate_summary(model, tokenizer, article)\n",
    "\n",
    "print(\"Original Article:\")\n",
    "print(article)\n",
    "print(\"\\nGenerated Summary:\")\n",
    "print(generated_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9b3dd-aea1-4c9a-bda3-7c9e2f8c5988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
