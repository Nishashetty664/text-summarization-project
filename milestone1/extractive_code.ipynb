{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKcmj40cWjAaZ/kztT5qbF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# extractive summarization using text rank"],"metadata":{"id":"Bels9VNNSY6a"}},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4M_0PyTlR9SW","executionInfo":{"status":"ok","timestamp":1720543658625,"user_tz":-330,"elapsed":3506,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}},"outputId":"060161e3-d671-4ca8-b244-7d8bbd25fa72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n"]},{"cell_type":"markdown","source":["## install libraries"],"metadata":{"id":"FnlQ1qPOSktn"}},{"cell_type":"code","source":["! pip install pandas numpy nltk networkx\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coqbF7LxSYoi","executionInfo":{"status":"ok","timestamp":1720543666140,"user_tz":-330,"elapsed":7519,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}},"outputId":"e0f7d890-fdbe-444a-8813-036749f0e9b2"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"cell_type":"markdown","source":["## Load and Preprocess Data"],"metadata":{"id":"2Qz09dW7SuKM"}},{"cell_type":"code","source":["import pandas as pd  # Importing pandas library for data manipulation and analysis\n","import numpy as np   # Importing numpy library for numerical operations\n","import nltk          # Importing NLTK (Natural Language Toolkit) for natural language processing tasks\n","nltk.download('punkt')  # Downloading the 'punkt' tokenizer models used by NLTK for sentence and word tokenization\n","from nltk.tokenize import sent_tokenize, word_tokenize  # Importing specific tokenization functions from NLTK\n","from nltk.corpus import stopwords  # Importing NLTK's stopwords corpus for filtering out common words\n","import networkx as nx  # Importing NetworkX library for graph-based algorithms like PageRank\n","\n","\n"],"metadata":{"id":"tTBtN5gtSy07","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720543666141,"user_tz":-330,"elapsed":8,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}},"outputId":"ab6e76d5-08df-45e0-d478-4c112aaf6571"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Download NLTK data files (if not already downloaded)\n","nltk.download('punkt')  # Download NLTK's punkt tokenizer\n","nltk.download('stopwords')  # Download NLTK's stopwords\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlAwqpV5W6o4","executionInfo":{"status":"ok","timestamp":1720543666141,"user_tz":-330,"elapsed":7,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}},"outputId":"4059727a-e0d7-4ee5-dcef-9762a6cd89e9"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["## Tokenize Sentences and Words"],"metadata":{"id":"tB3VJEqWUDtT"}},{"cell_type":"code","source":["# Function to read the dataset\n","def read_dataset(file_path):\n","    # Read CSV file into a DataFrame\n","    return pd.read_csv(file_path)  # Returns a DataFrame containing the dataset\n","\n","# Function to preprocess text into sentences\n","def preprocess_text(text):\n","    # Tokenize text into sentences\n","    sentences = sent_tokenize(text)\n","    return sentences  # Returns a list of sentences\n"],"metadata":{"id":"PhwQ0cnXUIG9","executionInfo":{"status":"ok","timestamp":1720543666141,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["## Build Similarity Matrix"],"metadata":{"id":"yujg3csRUMBM"}},{"cell_type":"code","source":["# Function to calculate similarity between two sentences using cosine similarity\n","def sentence_similarity(sent1, sent2):\n","    stop_words = set(stopwords.words('english'))  # Get English stopwords\n","    # Tokenize and remove stopwords\n","    sent1 = [w.lower() for w in word_tokenize(sent1) if w.lower() not in stop_words]\n","    sent2 = [w.lower() for w in word_tokenize(sent2) if w.lower() not in stop_words]\n","\n","    all_words = list(set(sent1 + sent2))  # Get all unique words from both sentences\n","\n","    # Initialize vectors for word counts\n","    vector1 = [0] * len(all_words)\n","    vector2 = [0] * len(all_words)\n","\n","    # Count word occurrences in each sentence\n","    for w in sent1:\n","        vector1[all_words.index(w)] += 1\n","    for w in sent2:\n","        vector2[all_words.index(w)] += 1\n","\n","    # Compute cosine similarity between the vectors\n","    similarity = cosine_similarity([vector1], [vector2])[0][0]\n","    return similarity  # Returns a float representing the cosine similarity\n","# Example of building a similarity matrix of sentences based on a threshold\n","def build_similarity_matrix(sentences, threshold=0.2):\n","    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n","\n","    # Calculate similarity between all pairs of sentences\n","    for i in range(len(sentences)):\n","        for j in range(len(sentences)):\n","            if i != j:\n","                similarity = sentence_similarity(sentences[i], sentences[j])\n","                if similarity > threshold:\n","                    similarity_matrix[i][j] = similarity\n","\n","    return similarity_matrix  # Returns a 2D NumPy array (similarity matrix)\n","\n"],"metadata":{"id":"lEEUer4UURYQ","executionInfo":{"status":"ok","timestamp":1720543666141,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["## Apply TextRank Algorithm"],"metadata":{"id":"APNJdb-9UmJX"}},{"cell_type":"code","source":["# Function to generate summary using TextRank algorithm\n","def textrank_summarize(text, top_n=5):\n","    sentences = preprocess_text(text)  # Preprocess text into sentences\n","    similarity_matrix = build_similarity_matrix(sentences)  # Build similarity matrix based on sentences\n","\n","    # Convert similarity matrix to a graph\n","    similarity_graph = nx.from_numpy_array(similarity_matrix)\n","    scores = nx.pagerank(similarity_graph)  # Compute PageRank scores for ranking sentences\n","\n","    # Rank sentences based on PageRank scores\n","    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n","\n","    # Ensure that top_n does not exceed available sentences\n","    top_n = min(top_n, len(ranked_sentences))\n","\n","    # Select top N sentences for summary\n","    summary = ' '.join([ranked_sentences[i][1] for i in range(top_n)])\n","    return summary  # Returns a string (generated summary)\n"],"metadata":{"id":"xr4CDunqUokS","executionInfo":{"status":"ok","timestamp":1720543666141,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## Generate Summary"],"metadata":{"id":"HQ0nLH_8U08Q"}},{"cell_type":"code","source":["from tqdm import tqdm  # Import tqdm for progress bar visualizat\n","# Function to evaluate the generated summary against a reference summary\n","def evaluate_summary(generated_summary, reference_summary):\n","    generated_tokens = set(word_tokenize(generated_summary))  # Tokenize generated summary\n","    reference_tokens = set(word_tokenize(reference_summary))  # Tokenize reference summary\n","\n","    common_tokens = generated_tokens.intersection(reference_tokens)  # Find common tokens\n","\n","    # Calculate precision, recall, and F1 score based on token overlap\n","    if len(generated_tokens) == 0 or len(reference_tokens) == 0:\n","        return 0, 0, 0\n","\n","    precision = len(common_tokens) / len(generated_tokens)\n","    recall = len(common_tokens) / len(reference_tokens)\n","\n","    if precision + recall == 0:\n","        f1 = 0\n","    else:\n","        f1 = 2 * (precision * recall) / (precision + recall)\n","\n","    return precision, recall, f1  # Returns three floats (precision, recall, F1 score)\n","\n","# Main function to summarize texts in the dataset and evaluate the summaries\n","def main():\n","    file_path = '/content/drive/My Drive/train_data1.csv'  # Path to your dataset CSV file\n","\n","    summaries = []  # List to store generated summaries\n","    precisions = []  # List to store precision scores\n","    recalls = []  # List to store recall scores\n","    f1s = []  # List to store F1 scores\n","\n","    # Iterate through each row in the dataset\n","    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Summarizing\"):\n","        summary = textrank_summarize(row['article'], top_n=5)  # Generate summary for each article\n","        summaries.append(summary)  # Append generated summary to list\n","\n","        # Evaluate generated summary against reference summary (assumed in 'highlight' column)\n","        precision, recall, f1 = evaluate_summary(summary, row['highlight'])\n","        precisions.append(precision)  # Append precision score\n","        recalls.append(recall)  # Append recall score\n","        f1s.append(f1)  # Append F1 score\n","\n","    # Add generated summaries to the DataFrame\n","    df['summary'] = summaries\n","\n","    # Save DataFrame with summaries to a new CSV file\n","    df.to_csv('/content/drive/My Drive/summarized_train_data1.csv', index=False)\n","    print(\"Summarization complete. Summarized data saved to 'summarized_train_new1.csv'.\")\n","\n","    # Calculate average precision, recall, and F1 score\n","    avg_precision = sum(precisions) / len(precisions)\n","    avg_recall = sum(recalls) / len(recalls)\n","    avg_f1 = sum(f1s) / len(f1s)\n","\n","    # Print average evaluation scores\n","    print(f\"Average Precision: {avg_precision}\")\n","    print(f\"Average Recall: {avg_recall}\")\n","    print(f\"Average F1 Score: {avg_f1}\")\n","\n","# Execute main function if script is run directly\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktBLgPRBU21s","executionInfo":{"status":"ok","timestamp":1720543724242,"user_tz":-330,"elapsed":58106,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}},"outputId":"9f62aa1e-50bc-491c-a863-3950887be41e"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["Summarizing: 100%|██████████| 11490/11490 [00:55<00:00, 206.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Summarization complete. Summarized data saved to 'summarized_train_new1.csv'.\n","Average Precision: 0.11943901651820747\n","Average Recall: 0.8127170619817642\n","Average F1 Score: 0.20283625093778002\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Function to display summarized data\n","def display_summarized_data(file_path, num_records=2):\n","    # Read the summarized CSV file into a DataFrame\n","    df = pd.read_csv(file_path)\n","\n","    # Display the first num_records records\n","    print(f\"Displaying first {num_records} records from {file_path}:\")\n","    for i in range(num_records):\n","        print(f\"\\nRecord {i+1}:\")\n","        print(f\"Article:\\n{df.loc[i, 'article']}\")\n","        print(f\"\\nGenerated Summary:\\n{df.loc[i, 'summary']}\")\n","        print(f\"\\nReference Summary:\\n{df.loc[i, 'highlight']}\")\n","        print(\"\\n---\")\n","\n","# Example usage:\n","file_path = '/content/drive/My Drive/summarized_train_data1.csv'  # Replace with your actual file path\n","display_summarized_data(file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BwbDgcfkV5Sf","executionInfo":{"status":"ok","timestamp":1720543800444,"user_tz":-330,"elapsed":1193,"user":{"displayName":"Harshitha Shetty","userId":"09796862377684608525"}},"outputId":"d071df69-fdde-4b15-8c08-39d88785720e"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Displaying first 2 records from /content/drive/My Drive/summarized_train_data1.csv:\n","\n","Record 1:\n","Article:\n","ever noticed plane seats appear getting smaller smaller increasing numbers people taking skies experts questioning packed planes putting passengers risk say shrinking space aeroplanes uncomfortable putting health safety danger squabbling arm rest shrinking space planes putting health safety danger week us consumer advisory group set department transportation said public hearing government happy set standards animals flying planes doesnt stipulate minimum amount space humans world animals rights space food humans said charlie leocha consumer representative committee time dot faa take stand humane treatment passengers could crowding planes lead serious issues fighting space overhead lockers crashing elbows seat back kicking tests conducted faa use planes 31 inch pitch standard airlines decreased many economy seats united airlines 30 inches room airlines offer little 28 inches cynthia corbertt human factors researcher federal aviation administration conducts tests quickly passengers leave plane tests conducted using planes 31 inches row seats standard airlines decreased reported detroit news distance two seats one point seat point seat behind known pitch airlines stick pitch 31 inches fall united airlines 30 inches space gulf air economy seats 29 32 inches air asia offers 29 inches spirit airlines offers 28 inches british airways seat pitch 31 inches easyjet 29 inches thomsons short haul seat pitch 28 inches virgin atlantics 3031\n","\n","Generated Summary:\n","ever noticed plane seats appear getting smaller smaller increasing numbers people taking skies experts questioning packed planes putting passengers risk say shrinking space aeroplanes uncomfortable putting health safety danger squabbling arm rest shrinking space planes putting health safety danger week us consumer advisory group set department transportation said public hearing government happy set standards animals flying planes doesnt stipulate minimum amount space humans world animals rights space food humans said charlie leocha consumer representative committee time dot faa take stand humane treatment passengers could crowding planes lead serious issues fighting space overhead lockers crashing elbows seat back kicking tests conducted faa use planes 31 inch pitch standard airlines decreased many economy seats united airlines 30 inches room airlines offer little 28 inches cynthia corbertt human factors researcher federal aviation administration conducts tests quickly passengers leave plane tests conducted using planes 31 inches row seats standard airlines decreased reported detroit news distance two seats one point seat point seat behind known pitch airlines stick pitch 31 inches fall united airlines 30 inches space gulf air economy seats 29 32 inches air asia offers 29 inches spirit airlines offers 28 inches british airways seat pitch 31 inches easyjet 29 inches thomsons short haul seat pitch 28 inches virgin atlantics 3031\n","\n","Reference Summary:\n","experts question packed planes putting passengers risk us consumer advisory group says minimum space must stipulated safety tests conducted planes leg room airlines offer\n","\n","---\n","\n","Record 2:\n","Article:\n","drunk teenage boy rescued security jumping lions enclosure zoo western india rahul kumar 17 clambered enclosure fence kamla nehru zoological park ahmedabad began running towards animals shouting would kill mr kumar explained afterwards drunk thought id stand good chance predators next level drunk intoxicated rahul kumar 17 climbed lions enclosure zoo ahmedabad began running towards animals shouting today kill lion mr kumar sitting near enclosure suddenly made dash lions surprising zoo security intoxicated teenager ran towards lions shouting today kill lion lion kills zoo spokesman said guards earlier spotted close enclosure idea planing enter fortunately eight moats cross getting lions usually fell second one allowing guards catch take handed police brave fool fortunately mr kumar fell moat ran towards lions could rescued zoo security staff reaching animals stock image kumar later explained dont really know drunk thought id stand good chance police spokesman said cautioned sent psychiatric evaluation fortunately lions asleep zoo guards acted quickly enough prevent tragedy similar delhi last year 20yearold man mauled death tiger indian capital climbing enclosure city zoo\n","\n","Generated Summary:\n","drunk teenage boy rescued security jumping lions enclosure zoo western india rahul kumar 17 clambered enclosure fence kamla nehru zoological park ahmedabad began running towards animals shouting would kill mr kumar explained afterwards drunk thought id stand good chance predators next level drunk intoxicated rahul kumar 17 climbed lions enclosure zoo ahmedabad began running towards animals shouting today kill lion mr kumar sitting near enclosure suddenly made dash lions surprising zoo security intoxicated teenager ran towards lions shouting today kill lion lion kills zoo spokesman said guards earlier spotted close enclosure idea planing enter fortunately eight moats cross getting lions usually fell second one allowing guards catch take handed police brave fool fortunately mr kumar fell moat ran towards lions could rescued zoo security staff reaching animals stock image kumar later explained dont really know drunk thought id stand good chance police spokesman said cautioned sent psychiatric evaluation fortunately lions asleep zoo guards acted quickly enough prevent tragedy similar delhi last year 20yearold man mauled death tiger indian capital climbing enclosure city zoo\n","\n","Reference Summary:\n","drunk teenage boy climbed lion enclosure zoo west india rahul kumar 17 ran towards animals shouting today kill lion fortunately fell moat reaching lions rescued\n","\n","---\n"]}]}]}